{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BERT Sentiment Analysis Model Demonstration__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook demonstrates the BERT sentiment analysis model on user input text reviews. Simply run all code chunks and input a customer review when prompted at the last code chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopWords_nltk = set(stopwords.words('english'))\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "print(\"Using {}.\".format(device_name))\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    seed_val = 17\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epochs = 5\n",
    "    batch_size = 6\n",
    "    seq_length = 512\n",
    "    lr = 2e-5\n",
    "    eps = 1e-8\n",
    "    pretrained_model = 'bert-base-uncased'\n",
    "    test_size=0.15\n",
    "    random_state=42\n",
    "    add_special_tokens=True\n",
    "    return_attention_mask=True\n",
    "    pad_to_max_length=True\n",
    "    do_lower_case=False\n",
    "    return_tensors='pt'\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Random Seed and Initialize Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "device = config.device\n",
    "\n",
    "random.seed(config.seed_val)\n",
    "np.random.seed(config.seed_val)\n",
    "torch.manual_seed(config.seed_val)\n",
    "torch.cuda.manual_seed_all(config.seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(config.pretrained_model,\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "model.load_state_dict(torch.load(f'_BERT_epoch_2.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three sample text reviews extracted from the \"unique_data.csv\" test dataset to showcase the sentiment analysis model. Feel free to input your own custom text reviews to test the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Coffee was fine, but nothing spectacular.\n",
      "Predicted Sentiment: Neutral\n"
     ]
    }
   ],
   "source": [
    "# negative test example (1 star): Fail...'nuff said.\n",
    "# neutral test example (3 stars): Coffee was fine, but nothing spectacular.\n",
    "# positive test example (5 stars): Great food. Everything we ordered was delicious. Exceptional service. Will definitely return next time we're in the area.\n",
    "\n",
    "# enter a review or piece of text to be analzyed\n",
    "sample_review = input(\"Please enter a sample text review: \")\n",
    "\n",
    "# prediction code for a single peice of text\n",
    "encoded_data_test_single = tokenizer.batch_encode_plus(\n",
    "[sample_review],\n",
    "add_special_tokens=config.add_special_tokens,\n",
    "return_attention_mask=config.return_attention_mask,\n",
    "pad_to_max_length=config.pad_to_max_length,\n",
    "max_length=config.seq_length,\n",
    "truncation=True,\n",
    "return_tensors=config.return_tensors\n",
    ")\n",
    "input_ids_test = encoded_data_test_single['input_ids']\n",
    "attention_masks_test = encoded_data_test_single['attention_mask']\n",
    "\n",
    "inputs = {'input_ids':      input_ids_test.to(device),\n",
    "          'attention_mask':attention_masks_test.to(device),\n",
    "         }\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "prediction = np.argmax(np.concatenate([outputs[0].detach().cpu().numpy()], axis=0), axis=1).flatten()[0]\n",
    "\n",
    "# print sentiment\n",
    "print(f\"Review: {sample_review}\")\n",
    "print(\"Predicted Sentiment: \" + [\"Negative\", \"Neutral\", \"Positive\"][prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
